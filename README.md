## About

This repository contains the code, the data, and the two demo pages for the paper *"Monaural Score-Informed Source Separation of Sound Mixtures of Two Guitars"*. | [**Demo Page**](https://chiahohsiung.github.io/Score-Informed-SS-on-Guitars/) | 

This work aims to separate the sounds generated by two guitars. In contrast to separating the sounds of different instruments, this task is much more challenging since the timbre differences are subtle and the pitch range is the same. Therefore, we opt to approach this problem in a **score-informed** setting. In other words, the score of the target guitar is given to the model as side information. We aim to train our model to be insensitive to timbre to deal with the rich diversity of guitar timbre in guitar music. 

We have two demo pages.  In the first demo page, the audio samples are selected to give an overall impression of the performance difference between the proposed method and an existing blind method.  In the second demo page, which can be considered more like as providing supplementary material to the paper, audio samples are selected from each of the five scenarios discussed and tested in the paper. More detailed descriptions are provided in the demo pages.

## The Model
![Score-Informed Model](/images/model_and_spec.png)
## Implementation
To implement our score-informed version of Open-Unmix [1], please first clone the original [**Open-Unmix repo**](https://github.com/sigsep/open-unmix-pytorch). And replace the files *data.py, model.py, train.py,* and *test.py* to their counterparts in this repo. To train and test the model, please follow these [**docs**](https://github.com/sigsep/open-unmix-pytorch/blob/master/docs).

## Results

### Comparison with score-informed CNN autoencoder [2] and score-informed U-Net [3] baselines

<img src="/images/low_res.png" width="40%">

### Comparison with score-informed U-Net in a more modern setting 

<img src="/images/modern.png" width="40%">

### Comparison with *blind* version of Open-unmix

<img src="/images/unseen.png" width="80%">

## Reference
[1] *F.-R. St ̈oter, S. Uhlich, A. Liutkus, and Y. Mitsufuji, “Open-Unmix - A reference implementation for music source separation,”Journal of OpenSource Software, vol. 4, no. 41, p. 1667, 2019.*

[2] *M. Miron, J. Janer, and E. G´omez, “Monaural scoreinformed source separation for classical music using convolutional neural network,” in Proc. ISMIR, pp. 55–
62, 2018.*

[3] *A. Jansson, E. Humphrey, N. Montecchio, R. Bittner, A. Kumar, and T. Weyde, “Singing voice separation with deep U-Net convolutional networks,” in Proc. ISMIR, 2017.*




